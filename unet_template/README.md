# U-Net Implementation

PyTorch implementation of **U-Net: Convolutional Networks for Biomedical Image Segmentation** (MICCAI 2015)

## ğŸ“„ Paper Information

- **Title**: U-Net: Convolutional Networks for Biomedical Image Segmentation
- **Authors**: Olaf Ronneberger, Philipp Fischer, Thomas Brox (University of Freiburg)
- **Conference**: MICCAI 2015
- **Paper**: [arXiv:1505.04597](https://arxiv.org/abs/1505.04597)

## ğŸ¯ Key Contributions

### 1. U-Shaped Architecture
- **Encoder (Contracting Path)**: íŠ¹ì§• ì¶”ì¶œ ë° ë‹¤ìš´ìƒ˜í”Œë§
- **Decoder (Expanding Path)**: ì—…ìƒ˜í”Œë§ ë° ì •ë°€í•œ ìœ„ì¹˜ ì •ë³´ ë³µì›
- **Skip Connections**: Encoderì˜ high-resolution featuresë¥¼ Decoderë¡œ ì „ë‹¬

### 2. Architecture Overview

```
Input (1Ã—572Ã—572)
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Encoder (Contracting Path) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Conv-Conv â†’ MaxPool (64 channels, 568Ã—568 â†’ 284Ã—284)     â”‚â”€â”€â”
â”‚  Conv-Conv â†’ MaxPool (128 channels, 280Ã—280 â†’ 140Ã—140)    â”‚  â”‚
â”‚  Conv-Conv â†’ MaxPool (256 channels, 136Ã—136 â†’ 68Ã—68)      â”‚  â”‚
â”‚  Conv-Conv â†’ MaxPool (512 channels, 64Ã—64 â†’ 32Ã—32)        â”‚  â”‚
â”‚  Conv-Conv (1024 channels, 28Ã—28) â† Bottleneck            â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                                                                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Decoder (Expanding Path) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  UpConv â†’ Concat â† Skip Connection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”˜
â”‚  Conv-Conv (512 channels, 52Ã—52)                           â”‚  â”‚
â”‚  UpConv â†’ Concat â† Skip Connection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”˜
â”‚  Conv-Conv (256 channels, 100Ã—100)                         â”‚  â”‚
â”‚  UpConv â†’ Concat â† Skip Connection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”˜
â”‚  Conv-Conv (128 channels, 196Ã—196)                         â”‚  â”‚
â”‚  UpConv â†’ Concat â† Skip Connection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”˜
â”‚  Conv-Conv (64 channels, 388Ã—388)                          â”‚
â”‚  1Ã—1 Conv â†’ Output (num_classes, 388Ã—388)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. Why U-Net Works?

1. **Skip Connections**: Low-level spatial information + High-level semantic information
2. **Symmetric Architecture**: Encoderì™€ Decoderì˜ ê· í˜•ìˆëŠ” êµ¬ì¡°
3. **Data Augmentation**: ì ì€ ë°ì´í„°ë¡œë„ í•™ìŠµ ê°€ëŠ¥ (elastic deformation)
4. **Overlap-Tile Strategy**: í° ì´ë¯¸ì§€ë¥¼ íŒ¨ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬

## ğŸ—ï¸ Model Variants

| Variant | Input Size | Channels | Use Case |
|---------|-----------|----------|----------|
| U-Net (Original) | 572Ã—572 | [64,128,256,512,1024] | Medical Image |
| U-Net (Modified) | 256Ã—256 | [64,128,256,512,1024] | General Segmentation |
| U-Net Small | 128Ã—128 | [32,64,128,256,512] | Fast Inference |

## ğŸ“ File Structure

```
unet/
â”œâ”€â”€ __init__.py          # Package initialization
â”œâ”€â”€ blocks.py            # DoubleConv, Down, Up, OutConv ì •ì˜
â”œâ”€â”€ model.py             # U-Net ëª¨ë¸ ì •ì˜
â”œâ”€â”€ train.py             # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ README.md            # This file
```

## ğŸš€ Usage

### 1. Import Model
```python
from unet import UNet

# Create model
model = UNet(in_channels=3, num_classes=2)  # Binary segmentation
model = UNet(in_channels=1, num_classes=21)  # 21-class segmentation
```

### 2. Forward Pass
```python
import torch

x = torch.randn(1, 3, 256, 256)  # [batch, channels, height, width]
output = model(x)  # [1, num_classes, 256, 256]

# For binary segmentation
probs = torch.sigmoid(output)  # Pixel-wise probabilities
```

### 3. Training (Custom Dataset)
```bash
cd unet
python train.py
```

## ğŸ’¡ Learning Points (TODO êµ¬í˜„í•˜ë©´ì„œ ë°°ìš¸ ë‚´ìš©)

### 1. Encoder-Decoder Architecture
- Contracting pathì˜ ì—­í•  (íŠ¹ì§• ì¶”ì¶œ)
- Expanding pathì˜ ì—­í•  (ìœ„ì¹˜ ì •ë³´ ë³µì›)
- ëŒ€ì¹­ êµ¬ì¡°ì˜ ì˜ë¯¸

### 2. Skip Connections
- ResNetì˜ residual connectionê³¼ì˜ ì°¨ì´
- Concatenation vs Addition
- High-resolution features ë³´ì¡´ì˜ ì¤‘ìš”ì„±

### 3. Upsampling Methods
- Transposed Convolution (Deconvolution)
- Upsampling + Convolution
- Bilinear Interpolation
- ê° ë°©ë²•ì˜ ì¥ë‹¨ì 

### 4. Segmentation Techniques
- Pixel-wise classification
- Cross-Entropy Loss for segmentation
- IoU (Intersection over Union) metric
- Dice Coefficient

## ğŸ”¬ Implementation Details

### Network Architecture (Original Paper)

```
Encoder:
- Double Conv (3â†’64): 3Ã—3 conv, ReLU, 3Ã—3 conv, ReLU
- MaxPool 2Ã—2
- Double Conv (64â†’128)
- MaxPool 2Ã—2
- Double Conv (128â†’256)
- MaxPool 2Ã—2
- Double Conv (256â†’512)
- MaxPool 2Ã—2

Bottleneck:
- Double Conv (512â†’1024)

Decoder:
- Up-conv 2Ã—2 (1024â†’512)
- Concatenate with encoder features
- Double Conv (1024â†’512)
- Up-conv 2Ã—2 (512â†’256)
- Concatenate with encoder features
- Double Conv (512â†’256)
- Up-conv 2Ã—2 (256â†’128)
- Concatenate with encoder features
- Double Conv (256â†’128)
- Up-conv 2Ã—2 (128â†’64)
- Concatenate with encoder features
- Double Conv (128â†’64)
- 1Ã—1 conv (64â†’num_classes)
```

### Training Hyperparameters

- **Optimizer**: SGD with momentum (0.99)
- **Loss**: Cross-Entropy (or Dice Loss for medical imaging)
- **Learning rate**: High momentum, no learning rate decay
- **Data augmentation**:
  - Elastic deformation
  - Random rotations, shifts
  - Brightness/contrast adjustment

### Modified U-Net (Practical Version)

Original U-Netì€ ì…ë ¥ í¬ê¸°ê°€ ì¤„ì–´ë“œëŠ” ë¬¸ì œê°€ ìˆìŒ (572â†’388).
ì‹¤ì œë¡œëŠ” paddingì„ ì¶”ê°€í•˜ì—¬ ì…ë ¥ê³¼ ì¶œë ¥ í¬ê¸°ë¥¼ ë™ì¼í•˜ê²Œ ìœ ì§€:

- ëª¨ë“  convì— `padding=1` ì¶”ê°€
- Input size = Output size (e.g., 256Ã—256 â†’ 256Ã—256)

## ğŸ“Š Expected Results

### ISBI Cell Tracking Challenge
- **IoU**: > 0.92
- **Warping Error**: < 1.5

### Common Datasets
- **Carvana (Car Segmentation)**: Dice > 0.99
- **Cityscapes (Street Scene)**: mIoU > 65%

## ğŸ“ Key Takeaways

1. **Symmetric Design**: Encoder-Decoder êµ¬ì¡°ì˜ ê· í˜•ì´ ì¤‘ìš”
2. **Skip Connections**: Spatial information ë³´ì¡´ì˜ í•µì‹¬
3. **Flexible Architecture**: ë‹¤ì–‘í•œ í•´ìƒë„/ì±„ë„ ìˆ˜ì— ì ìš© ê°€ëŠ¥
4. **Medical Imaging**: ì ì€ ë°ì´í„°ë¡œë„ ê°•ë ¥í•œ ì„±ëŠ¥

## ğŸ”— References

- [Original Paper](https://arxiv.org/abs/1505.04597)
- [PyTorch Example](https://github.com/milesial/Pytorch-UNet)
- [TensorFlow Implementation](https://www.tensorflow.org/tutorials/images/segmentation)

## ğŸ“ TODO Checklist

í•™ìŠµì„ ìœ„í•´ ë‹¤ìŒ ë¶€ë¶„ë“¤ì„ ì§ì ‘ êµ¬í˜„í•´ë³´ì„¸ìš”:

### blocks.py
- [ ] DoubleConv: 3x3 conv â†’ ReLU â†’ 3x3 conv â†’ ReLU
- [ ] Down: MaxPool â†’ DoubleConv
- [ ] Up: Upsampling â†’ Conv â†’ Concatenate â†’ DoubleConv
- [ ] OutConv: 1x1 convolution for final output

### model.py
- [ ] Encoder path (4ê°œì˜ Down blocks)
- [ ] Bottleneck (ê°€ì¥ ê¹Šì€ ì¸µ)
- [ ] Decoder path (4ê°œì˜ Up blocks)
- [ ] Skip connections (concatenation)
- [ ] Forward pass ì „ì²´ êµ¬í˜„

### train.py
- [ ] Segmentation dataset ë¡œë”©
- [ ] IoU/Dice metric êµ¬í˜„
- [ ] Training loop
- [ ] Validation loop
- [ ] Segmentation ê²°ê³¼ ì‹œê°í™”

---

â­ **Tip**: êµ¬í˜„í•˜ë©´ì„œ ë§‰íˆë©´ ë…¼ë¬¸ì˜ Figure 1ì„ ì°¸ê³ í•˜ì„¸ìš”!
